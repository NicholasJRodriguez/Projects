{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126ad23e-b3b6-40ca-863d-7d4984fb3ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data transformation 1 removes extra symbols from column headers and simplifies headers.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# load the csv\n",
    "file_path = \"pokemon.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Clean column headers by removing extra symbols\n",
    "df.columns = df.columns.str.replace(r'[^a-zA-Z0-9]', '', regex=True)\n",
    "\n",
    "# Display cleaned column headers\n",
    "print(df.columns.tolist())\n",
    "\n",
    "# Data transformation 2 removes leading zeros from all row entries.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# load the csv\n",
    "file_path = \"pokemon.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Function to remove leading zeros from all string and numerical entries\n",
    "def remove_all_leading_zeros(val):\n",
    "    try:\n",
    "        val_str = str(val)\n",
    "        val_str_no_zeros = val_str.lstrip('0')\n",
    "        if val_str_no_zeros.replace('.', '', 1).isdigit():\n",
    "            return int(val_str_no_zeros) if '.' not in val_str_no_zeros else float(val_str_no_zeros)\n",
    "        return val_str_no_zeros\n",
    "    except Exceptiopn:\n",
    "        return val\n",
    "\n",
    "# Apply to the entire DataFrame\n",
    "for col in df.columns:\n",
    "    df[col] = df[col].map(remove_all_leading_zeros)\n",
    "\n",
    "# Display\n",
    "print(df.head())\n",
    "\n",
    "# Data transformation 3 removes the classification and abilities columns, as it is unnecessary to research my project topic.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# load the csv\n",
    "file_path = \"pokemon.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Remove 'classification' and 'abilities' columns\n",
    "df = df.drop(columns=['classfication', 'abilities'])\n",
    "\n",
    "# Display remaining columns\n",
    "print(\"Remaining Columns:\")\n",
    "print(df.columns.tolist())\n",
    "\n",
    "# Data transformation 4 removes the 'japanese_name' column as it is redundant and adds unnecessary complexity to the dataset when researching my project topic.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# load the csv\n",
    "file_path = \"pokemon.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Remove the 'japanese_name' column\n",
    "df = df.drop(columns=['japanese_name'])\n",
    "\n",
    "# Display\n",
    "print(\"Remaining Columns:\")\n",
    "print(df.columns.tolist())\n",
    "\n",
    "# Data transformation 5 searches for and fills all missing values.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# load the csv\n",
    "file_path = \"pokemon.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Fill missing values, 0 for numerical and 'Unknown' for string entries\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'object':\n",
    "        df[col] = df[col].fillna('Unknown')\n",
    "    else:\n",
    "        df[col] = df[col].fillna(0)\n",
    "\n",
    "# Confirm no missing values remain\n",
    "print(\"Remaining missing values:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Data transformation 6 normalizes all stats from 0 to 1 for consistency and comparison. Should I need it, this will allow for more useful machine learning models and visualizations.\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# load the csv\n",
    "file_path = \"pokemon.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Normalize stats using MinMaxScaler\n",
    "stat_columns = ['hp', 'attack', 'defense', 'sp_attack', 'sp_defense', 'speed']\n",
    "stat_columns_cleaned = [col for col in stat_columns if col in df.columns]\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "df[stat_columns_cleaned] = scaler.fit_transform(df[stat_columns_cleaned])\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "# Human-readable dataset after all transformations\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# load the csv\n",
    "file_path = \"pokemon.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Clean column headers by removing extra symbols\n",
    "df.columns = df.columns.str.replace(r'[^a-zA-Z0-9]', '', regex=True)\n",
    "\n",
    "# Function to remove leading zeros from all string and numerical entries\n",
    "def remove_all_leading_zeros(val):\n",
    "    try:\n",
    "        val_str = str(val)\n",
    "        val_str_no_zeros = val_str.lstrip('0')\n",
    "        if val_str_no_zeros.replace('.', '', 1).isdigit():\n",
    "            return int(val_str_no_zeros) if '.' not in val_str_no_zeros else float(val_str_no_zeros)\n",
    "        return val_str_no_zeros\n",
    "    except Exceptiopn:\n",
    "        return val\n",
    "\n",
    "# Apply to the entire DataFrame\n",
    "for col in df.columns:\n",
    "    df[col] = df[col].map(remove_all_leading_zeros)\n",
    "\n",
    "# Remove 'classification', 'abilities', and 'japanese_name' columns\n",
    "columns_to_remove = ['classfication', 'abilities', 'japanesename']\n",
    "df = df.drop(columns=columns_to_remove)\n",
    "\n",
    "\n",
    "# Fill missing values\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'object':\n",
    "        df[col] = df[col].fillna('Unknown')\n",
    "    else:\n",
    "        df[col] = df[col].fillna(0)\n",
    "\n",
    "# Normalize stats using MinMaxScaler\n",
    "stat_columns = ['hp', 'attack', 'defense', 'sp_attack', 'sp_defense', 'speed']\n",
    "stat_columns_cleaned = [col for col in stat_columns if col in df.columns]\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "df[stat_columns_cleaned] = scaler.fit_transform(df[stat_columns_cleaned])\n",
    "\n",
    "# Human-readable output\n",
    "print(\"Transformations Applied:\")\n",
    "print(\"1. Cleaned all column headers by removing symbols and underscores)\")\n",
    "print(\"2. Removed leading zeros from all row entries\")\n",
    "print(\"3. Removed columns: {columns_to_remove}\")\n",
    "print(\"4. Filled missing values\")\n",
    "print(\"5. Normalized stat columns\\n\")\n",
    "\n",
    "print(\"Transformed data:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a0dd31-276f-4b81-b3ca-3fdc5ee7ddaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and clean the raw data from the HTML\n",
    "\n",
    "# Identify and isolate the table containing Generation 1 Pokémon data\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Fetch and parse the HTML\n",
    "url = \"https://serebii.net/pokemon/gen1pokemon.shtml\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "# Data containers\n",
    "stats = []\n",
    "numbers = [] # Store associated numerical (No.) for each Pokémon\n",
    "\n",
    "# Find the table that contains the necessary Pokémon data \n",
    "tables = soup.find_all(\"table\", class_=\"dextable\") # Subject to update as website changes\n",
    "\n",
    "# Extract and format the data into a more readable format\n",
    "for table in tables:\n",
    "    rows = table.find_all(\"tr\")\n",
    "    for row in rows[1:]: # Extract rows skipping header rows\n",
    "        try:\n",
    "            tds = row.find_all(\"td\")\n",
    "            if len(tds) < 12:\n",
    "                continue\n",
    "            \n",
    "            # Extract each Pokémon associated No.\n",
    "            number_text = tds[0].text.strip()\n",
    "            number = number_text if number_text.startswith(\"#\") else None\n",
    "\n",
    "            # Extract stats from HP to Speed\n",
    "            stat_cells = tds[6:12] # HP starts from tds[6]\n",
    "            base_stats = [int(cell.text.strip()) if cell.text.strip().isdigit() else 0 for cell in stat_cells]\n",
    "\n",
    "            if number and len(base_stats) == 6:\n",
    "                stats.append(base_stats)\n",
    "                numbers.append(number)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "# Transformation 1, construction of the DataFrame\n",
    "df = pd.DataFrame({\n",
    "    \"HP\": [s[0] for s in stats],\n",
    "    \"Attack\": [s[1] for s in stats],\n",
    "    \"Defense\": [s[2] for s in stats],\n",
    "    \"S.Attack\": [s[3] for s in stats],\n",
    "    \"S.Defense\": [s[4] for s in stats],\n",
    "    \"Speed\": [s[5] for s in stats],\n",
    "    \"Pokemon No.\": numbers\n",
    "})\n",
    "# Description: I created a data frame with each Pokémon's stats (HP, Attack, etc.) and included the Pokémon's Number in the Pokedex. This will give the necessary structure to manipulate and analyze the data.\n",
    "\n",
    "# Transformation 2, sort Pokémon numbers\n",
    "df.sort_values(by=\"Pokemon No.\", inplace=True)\n",
    "# Description: This will prepare the Pokémon No.'s so that I can cleanly extract integer values for the next transformation. This will also ensure consistency in the data structure for future transformations.\n",
    "\n",
    "# Transformation 3, reindex the DataFrame\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "# Description: After sorting, I reset the index to keep the DataFrame clean. This avoids working with indices that don't reflect order.\n",
    "\n",
    "# Transformation 4, convert Pokémon No. from '#0001' to an integer 1 to 151\n",
    "df['Pokemon No.'] = df['Pokemon No.'].apply(lambda x: int(x[1:]) if isinstance(x, str) and x.startswith('#') else x)\n",
    "# Description: I converted Pokemon numbers from a string '#0001' to an integer. So, '#0001' will be 1, and so on. This will simplify sorting, filtering, and make the display straightforward.\n",
    "\n",
    "# Transformation 5, calculate a combined stat\n",
    "df['Combined Stat'] = df[['HP', 'Attack', 'Defense', 'S.Attack', 'S.Defense', 'Speed']].sum(axis=1)\n",
    "df['Normalized Combined Stat'] = (df['Combined Stat'] - df['Combined Stat'].min()) / (df['Combined Stat'].max() - df['Combined Stat'].min())\n",
    "# Description: I decided to calculate a single metric that sums up all the stats for a Pokémon. This will allow for a clean single integer for analysis and plotting. Then I normalize the total on a 0 to 1 scale for logical comparisons.\n",
    "\n",
    "# Transformation 6, plot the combined stats by Pokémon No.\n",
    "plt.figure(figsize=(15, 6))\n",
    "bars = plt.bar(df['Pokemon No.'], df['Combined Stat'])\n",
    "plt.xticks(range(0, len(df), 5)) # Show every 5th Pokemon for better readability\n",
    "plt.xlabel('Pokemon No.')\n",
    "plt.ylabel('Stats Combined')\n",
    "plt.title('Pokemon Generation 1: Combined Base Stats')\n",
    "plt.tight_layout()\n",
    "# Description: Display of the data transformations via a visual graphic. This is necessary to provide insight into each Pokémon's combined stats in a quick view and will make referencing each Pokémon easier for additional analysis. \n",
    "\n",
    "# Annotate bars with values\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, height + 1, f\"{height}\", ha='center', va='bottom')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Human-readable output\n",
    "print(\"\\nFinal Pokemon Dataset Preview:\")\n",
    "print(df[['Pokemon No.', 'HP', 'Attack', 'Defense', 'S.Attack', 'S.Defense', 'Speed', 'Combined Stat', 'Normalized Combined Stat']].head())\n",
    "\n",
    "# Locate the necessary table\n",
    "tables = soup.find_all('table')\n",
    "for i, table in enumerate(tables):\n",
    "    print(f\"Table {i}:\")\n",
    "    rows = table.find_all(\"tr\")\n",
    "    for row in rows[:5]:\n",
    "        print(row)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc5b48c-2ae9-414a-baa8-0417b9d12716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation 1, filter out unnecessary data\n",
    "\n",
    "import requests\n",
    "\n",
    "# API base URL\n",
    "pokeapi_url = \"https://pokeapi.co/api/v2/pokemon/\"\n",
    "\n",
    "# Function to fetch Pokémon data\n",
    "def get_pokemon_data(pokemon_id):\n",
    "    response = requests.get(f\"{pokeapi_url}{pokemon_id}\")\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        return {\n",
    "        \"name\": data[\"name\"],\n",
    "        \"types\": [t[\"type\"][\"name\"] for t in data [\"types\"]],\n",
    "        \"stats\": {stat[\"stat\"][\"name\"]: stat[\"base_stat\"] for stat in data[\"stats\"]}\n",
    "        }\n",
    "    else:\n",
    "        print(f\"Failed to retrieve Pokemon {pokemon_id}\")\n",
    "        return None\n",
    "\n",
    "# Fetch the first 151 Pokémon\n",
    "pokemon_list = []\n",
    "for i in range(1, 152): # Pokemon 1 to 151\n",
    "\n",
    "    pokemon_data = get_pokemon_data(i)\n",
    "    if pokemon_data:\n",
    "        pokemon_list.append(pokemon_data)\n",
    "\n",
    "# Display some of the processed data\n",
    "print(f\"Retrieved {len(pokemon_list)} Pokemon.\")\n",
    "print(pokemon_list[:5]) # Show the first 5 Pokemon\n",
    "\n",
    "# Description: I requested Pokémon data from the pokeapi.co. I then only extract name, types, and stats from the JSON, as this is what I will need to best answer my project topic.\n",
    "\n",
    "# Transformation 2, normalize stat values for the first 151 Pokémon\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Extract all base stats\n",
    "all_stats = {stat: [p[\"stats\"][stat] for p in pokemon_list] for stat in pokemon_list[0][\"stats\"].keys()}\n",
    "\n",
    "# Computation for min and max of each base stat\n",
    "stat_min_max = {stat: (min(values), max(values)) for stat, values in all_stats.items()}\n",
    "\n",
    "# Normalize stat values\n",
    "for pokemon in pokemon_list:\n",
    "    pokemon[\"normalized_stats\"] = {\n",
    "        stat: round(\n",
    "            (pokemon[\"stats\"][stat] - stat_min_max[stat][0]) / (stat_min_max[stat][1] - stat_min_max[stat][0]), 2\n",
    "        )\n",
    "               for stat in pokemon[\"stats\"]\n",
    "               }\n",
    "# Display some of the normalized stats\n",
    "print(f\"Normalized stats for {pokemon_list[0]['name']}: {pokemon_list[0]['normalized_stats']}\")\n",
    "\n",
    "# Description: I pulled the stat values from the pokeapi.co JSON. Then, I rescale the stats from 0 to 1 to make comparisons easier to understand and more readable across Pokémon.\n",
    "\n",
    "# Transformation 3, group Pokémon by type\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "# Dictionary to store Pokémon by type\n",
    "type_groupings = defaultdict(list)\n",
    "\n",
    "# Group Pokémon by type\n",
    "for pokemon in pokemon_list:\n",
    "    type_1 = pokemon[\"types\"][0] if len(pokemon[\"types\"]) > 0 else \"Unknown\"\n",
    "    type_2 = pokemon[\"types\"][1] if len(pokemon[\"types\"]) > 1 else \"None\" # Handle for mono-type Pokemon\n",
    "\n",
    "    type_groupings[type_1].append(pokemon)\n",
    "    if type_2 != \"None\":\n",
    "        type_groupings[type_2].append(pokemon) # Add Pokémon to the second typing\n",
    "\n",
    "# Display some of the grouped Pokémon\n",
    "for pokemon_type, pokemons in list(type_groupings.items())[:5]: # Show the first 5 Pokemon\n",
    "    for p in pokemons[:5]: # Limiting output for readbility\n",
    "        print(f\"Pokémon: {p['name'].capitalize()}, Type 1: {p['types'][0]}, Type 2: {p['types'][1] if len(p['types']) > 1 else 'None'}\")\n",
    "\n",
    "# Description: I extract the type data from the JSON of the pokeapi.co. With the type data, I categorize the Pokémon by their types, ensuring to catch Pokémon that have more than 1 type and clearly labeling those that don't.\n",
    "\n",
    "# Transformation 4, handle missing or outlier data\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Identify missing stats\n",
    "missing_entries = [p[\"name\"] for p in pokemon_list if None in p[\"stats\"].values()]\n",
    "print(f\"Pokémon with missing stats: {missing_entries}\")\n",
    "\n",
    "# Compute thresholds for outlier detections\n",
    "stat_values = {stat: [p[\"stats\"][stat] for p in pokemon_list] for stat in pokemon_list[0][\"stats\"].keys()} \n",
    "stat_means = {stat: np.mean(values) for stat, values in stat_values.items()}\n",
    "stat_std_devs = {stat: np.std(values) for stat, values in stat_values.items()}\n",
    "\n",
    "# Flag outliers using z-score threshold\n",
    "outliers = {\n",
    "    stat: [\n",
    "        {\n",
    "            \"name\": p[\"name\"],\n",
    "            \"types\": \", \". join(p[\"types\"]), # Formatting for readbility\n",
    "            \"stat_value\": p[\"stats\"][stat],\n",
    "            \"z_score\": round((p[\"stats\"][stat] - stat_means[stat]) / stat_std_devs[stat], 2)\n",
    "        }\n",
    "        for p in pokemon_list if abs(p[\"stats\"][stat] - stat_means[stat]) > 3 * stat_std_devs[stat]\n",
    "    ]\n",
    "    for stat in stat_values.keys()\n",
    "}\n",
    "\n",
    "# Show flagged outliers\n",
    "for stat, pokemon_data in outliers.items():\n",
    "    print(f\"\\nOutliers in {stat}:\")\n",
    "    for p in pokemon_data:\n",
    "        print(f\"Pokémon: {p['name'].capitalize()}, Type(s): {p['types']}, {stat}: {p['stat_value']}, Z-score: {p['z_score']}\")\n",
    "\n",
    "# Description: I process the stats from the pokeapi.co JSON to account for missing or extreme values. The output also specifically names the Pokémon, its type(s), which specific stat is the outlier, and the Z-score to describe how significantly it differs from the average. \n",
    "\n",
    "# Transformation 5, calculate aggregates and prepare for visualization\n",
    "\n",
    "# Compute the average stats per type\n",
    "type_averages = {}\n",
    "\n",
    "for poke_type, pokemons in type_groupings.items():\n",
    "    stat_sums = {stat: sum(p[\"stats\"][stat] for p in pokemons) for stat in pokemons[0][\"stats\"].keys()}\n",
    "    stat_avgs = {stat: round(stat_sums[stat] / len(pokemons), 2) for stat in stat_sums}\n",
    "    type_averages[poke_type] = stat_avgs\n",
    "\n",
    "# Show the results\n",
    "for poke_type, stats in list(type_averages.items())[:5]: # Limiting output for readbility\n",
    "    print(f\"\\nType: {poke_type} \\nAverage Stats\")\n",
    "    for stat, avg in stats.items():\n",
    "        print(f\"{stat.capitalize()}: {avg}\")\n",
    "\n",
    "# Description: I calculate sums and averages from the pokeapi.co JSON, specifically Pokémon stats. The output organizes the aggregated values by type and displays the specific averages for easy comparison between types.\n",
    "\n",
    "# Human readable dataset after all transformations\n",
    "\n",
    "stat_categories = [\"hp\", \"attack\", \"defense\", \"special-attack\", \"special-defense\", \"speed\"]\n",
    "\n",
    "# Min-max normalization for each stat\n",
    "for stat in stat_categories:\n",
    "    stat_values = [p[\"stats\"][stat] for p in pokemon_list if stat in p[\"stats\"]]\n",
    "\n",
    "    # Find the min and max values for normalization\n",
    "    min_val, max_val = min(stat_values), max(stat_values)\n",
    "\n",
    "    # Apply normalization and assign to each Pokémon\n",
    "    for p in pokemon_list:\n",
    "        if stat in p[\"stats\"]: # Check to ensure Pokémon has the stat before modification\n",
    "            normalized_value = (p[\"stats\"][stat] - min_val) / (max_val - min_val)\n",
    "            if \"normalized_stats\" not in p:\n",
    "                p[\"normalized_stats\"] = {} # Normalized stats dictionary if missing\n",
    "            p[\"normalized_stats\"][stat] = round(normalized_value, 2) # Assign the normalized stats\n",
    "        \n",
    "import pandas as pd\n",
    "\n",
    "# Structured dataset with each relevant field\n",
    "final_data = []\n",
    "for p in pokemon_list:\n",
    "    if \"normalized_stats\" not in p:\n",
    "        continue # Skip Pokémon missing normalized stats\n",
    "\n",
    "    formatted_stats = {stat: p[\"normalized_stats\"].get(stat, \"N/A\") for stat in stat_categories}\n",
    "    \n",
    "    # Find stats where a Pokémon is flagged as an outlier\n",
    "    outlier_stats = [\n",
    "        stat for stat in outliers if p[\"name\"] in [o[\"name\"] for o in outliers[stat]]\n",
    "    ]\n",
    "\n",
    "    final_data.append({\n",
    "        \"Name\": p[\"name\"].capitalize(),\n",
    "        \"Type 1\": p[\"types\"][0],\n",
    "        \"Type 2\": p[\"types\"][1] if len(p[\"types\"]) > 1 else \"None\",\n",
    "        **formatted_stats,\n",
    "        \"Outlier Stats\": \", \".join(outlier_stats) if outlier_stats else \"None\"\n",
    "    })\n",
    "\n",
    "# Conversion to Pandas DataFrame for readability\n",
    "df = pd.DataFrame(final_data)\n",
    "\n",
    "# Show human readable dataset\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4655d3d5-6abd-4a5d-ac75-21315e3bb763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pokemon.db was created.\n"
     ]
    }
   ],
   "source": [
    "# Load my 3 cleaned and transformed datasets into a database using SQLite.\n",
    "\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "conn = sqlite3.connect(\"pokemon.db\")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Confirm creation of pokemon.db\n",
    "print(\"pokemon.db was created.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
